{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Loan_Prediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqIEDg2U9Fw5CjL/4fDnBo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiddharthaPand4/bad_loan_prediction/blob/main/Loan_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip senior_ds_test.zip"
      ],
      "metadata": {
        "id": "nuc41BZyv-9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iD-U3zLvyyL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_account_data(account_data, res):\n",
        "    for person_data in account_data:\n",
        "        uid = person_data[0][\"uid\"]\n",
        "        res[uid][\"total_loan_amount\"] = 0\n",
        "        res[uid][\"total_amount_overdue\"] = 0\n",
        "        res[uid][\"loans_running\"] = 0\n",
        "        res[uid][\"total_days_overdue\"] = 0\n",
        "        res[uid][\"credit_type_count\"] = {}\n",
        "        \n",
        "        for loan_data in person_data:\n",
        "            res[uid][\"total_loan_amount\"] += loan_data[\"loan_amount\"]\n",
        "\n",
        "            res[uid][\"total_amount_overdue\"] += loan_data[\"amount_overdue\"]\n",
        "\n",
        "            res[uid][\"loans_running\"] += 1 if not loan_data[\"closed_date\"] else 0\n",
        "\n",
        "            credit_type = loan_data[\"credit_type\"]\n",
        "            count = res[uid][\"credit_type_count\"].get(credit_type, 0)\n",
        "            res[uid][\"credit_type_count\"][credit_type] = count + 1\n",
        "\n",
        "            payment_hist = loan_data[\"payment_hist_string\"]\n",
        "            assert len(payment_hist) % 3 == 0\n",
        "            for i in range(0, len(payment_hist), 3):\n",
        "                due_days = int(payment_hist[i: i+3])\n",
        "                res[uid][\"total_days_overdue\"] += due_days\n",
        "        \n",
        "    return res"
      ],
      "metadata": {
        "id": "_uG8BfQXe43t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_enquiry_data(enquiry_data, account_data_dict):\n",
        "    for person_data in enquiry_data:\n",
        "        uid = person_data[0][\"uid\"]\n",
        "        if account_data_dict[uid].get(\"credit_type_count\", -1) == -1:\n",
        "            account_data_dict[uid][\"total_loan_amount\"] = 0\n",
        "            account_data_dict[uid][\"total_amount_overdue\"] = 0\n",
        "            account_data_dict[uid][\"loans_running\"] = 0\n",
        "            account_data_dict[uid][\"total_days_overdue\"] = 0\n",
        "            account_data_dict[uid][\"credit_type_count\"] = {}\n",
        "        \n",
        "        account_data_dict[uid][\"total_enquiry_amount\"] = 0\n",
        "        account_data_dict[uid][\"enquiry_type_count\"] = {}\n",
        "        for enquiry in person_data:\n",
        "            account_data_dict[uid][\"total_enquiry_amount\"] += enquiry[\"enquiry_amt\"]\n",
        "\n",
        "            enquiry_type = enquiry[\"enquiry_type\"]\n",
        "            count = account_data_dict[uid][\"enquiry_type_count\"].get(enquiry_type, 0)\n",
        "            account_data_dict[uid][\"enquiry_type_count\"][enquiry_type] = count + 1\n",
        "        \n",
        "    return account_data_dict"
      ],
      "metadata": {
        "id": "aBmB8YttfIKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(mode=\"train\", enquiry_index={}, credit_index={}):\n",
        "    train_flag = pd.read_csv(f\"./senior_ds_test/data/{mode}/{mode}_flag.csv\")\n",
        "    train_flag_list = train_flag.values.tolist()\n",
        "    applicant_data = {}\n",
        "    for row in train_flag_list:\n",
        "        applicant_data[row[0]] = {\n",
        "            \"contract_type\": row[1],\n",
        "            \"target\": row[2]\n",
        "        } if mode == \"train\" else {\n",
        "            \"contract_type\": row[1]\n",
        "        }\n",
        "    print(len(applicant_data))\n",
        "    json_file = open(f\"./senior_ds_test/data/{mode}/accounts_data_{mode}.json\")\n",
        "    data = json.loads(json_file.read())\n",
        "    account_data = preprocess_account_data(data, applicant_data)\n",
        "    print(len(account_data))\n",
        "    json_file = open(f\"./senior_ds_test/data/{mode}/enquiry_data_{mode}.json\")\n",
        "    data = json.loads(json_file.read())\n",
        "    applicant_data = preprocess_enquiry_data(data, account_data)\n",
        "    print(len(applicant_data))\n",
        "    enquiry_types = set()\n",
        "    for k,v in applicant_data.items():\n",
        "        for e in v[\"enquiry_type_count\"].keys():\n",
        "            enquiry_types.add(e)\n",
        "\n",
        "    print(len(enquiry_types))\n",
        "    enquiry_type_index = {e:i for i, e in enumerate(enquiry_types)}\n",
        "    print(enquiry_type_index)\n",
        "    credit_types = set()\n",
        "    for k,v in applicant_data.items():\n",
        "        for e in v[\"credit_type_count\"].keys():\n",
        "            credit_types.add(e)\n",
        "\n",
        "    print(len(credit_types))\n",
        "    credit_type_index = {e:i for i, e in enumerate(credit_types)}\n",
        "    print(credit_type_index)\n",
        "    train_data = []\n",
        "    uid_list = []\n",
        "    for uid, details in applicant_data.items():\n",
        "        total_loan_amount = details[\"total_loan_amount\"]\n",
        "        total_amount_overdue = details[\"total_amount_overdue\"]\n",
        "        loans_running = details[\"loans_running\"]\n",
        "        total_days_overdue = details[\"total_days_overdue\"]\n",
        "        total_enquiry_amount = details[\"total_enquiry_amount\"]\n",
        "        contract_type = details[\"contract_type\"] == \"Cash loans\"\n",
        "        if mode == \"train\":\n",
        "            target = details[\"target\"]\n",
        "\n",
        "        row = [total_loan_amount, total_amount_overdue, loans_running, total_days_overdue, \n",
        "               total_enquiry_amount, contract_type]\n",
        "\n",
        "        credit_type_counts = [0]*len(credit_types if mode==\"train\" else credit_index)\n",
        "        for c_type, count in details[\"credit_type_count\"].items():\n",
        "            credit_type_counts[credit_type_index[c_type] if mode==\"train\" else credit_index[c_type]] = count\n",
        "        row.extend(credit_type_counts)\n",
        "\n",
        "        enquiry_type_counts = [0]*len(enquiry_types if mode==\"train\" else enquiry_index)\n",
        "        for e_type, count in details[\"enquiry_type_count\"].items():\n",
        "            enquiry_type_counts[enquiry_type_index[e_type] if mode==\"train\" else enquiry_index[c_type]] = count\n",
        "        row.extend(enquiry_type_counts)\n",
        "        if mode == \"train\":\n",
        "            row.append(target)\n",
        "        else:\n",
        "            uid_list.append(uid)\n",
        "        train_data.append(row)\n",
        "\n",
        "    arr_data = np.array(train_data)\n",
        "    arr_data = arr_data[~np.isnan(arr_data).any(axis=1)]\n",
        "    print(type(arr_data))\n",
        "    print(arr_data.shape)\n",
        "    uid_arr = np.array(uid_list)\n",
        "    return arr_data, enquiry_type_index, credit_type_index, uid_arr"
      ],
      "metadata": {
        "id": "d6aFvtTEeej7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, enquiry_type_index, credit_type_index, uids = load_data(mode=\"train\")\n",
        "print()\n",
        "print(\"test data starts now\")\n",
        "print()\n",
        "test_data, _, _, test_uids = load_data(\"test\", enquiry_type_index, credit_type_index)"
      ],
      "metadata": {
        "id": "EqSI-4MLgUXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.shape)"
      ],
      "metadata": {
        "id": "Z4r23gtjmp3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_data = data[data[:, data.shape[1]-1]==1]\n",
        "pos_data.shape"
      ],
      "metadata": {
        "id": "vMZ_2smqlIax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_pos_data = data[data[:, 36]==0]\n",
        "print(non_pos_data.shape)\n",
        "\n",
        "idx = np.random.randint(non_pos_data.shape[0], size=pos_data.shape[0])\n",
        "neg_data = non_pos_data[idx, :]\n",
        "print(neg_data.shape)"
      ],
      "metadata": {
        "id": "6DtTVCAPlIaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.concatenate((pos_data, neg_data))\n",
        "np.random.shuffle(data)\n",
        "\n",
        "print(data.shape)\n",
        "print(type(data))"
      ],
      "metadata": {
        "id": "66hIruWulIa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = 0.8\n",
        "train = data[:int(split*data.shape[0])]\n",
        "val = data[int(split*data.shape[0]):int(0.9*data.shape[0])]\n",
        "test = data[int(0.9*data.shape[0]):]\n",
        "print(data.shape, train.shape, val.shape, test.shape)"
      ],
      "metadata": {
        "id": "FLNzXHFelIa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, train_y = train[:, :train.shape[1]-1], train[:, train.shape[1]-1]\n",
        "print(train_x.shape, train_y.shape)\n",
        "val_x, val_y = val[:, :val.shape[1]-1], val[:, val.shape[1]-1]\n",
        "print(val_x.shape, val_y.shape)\n",
        "test_x, test_y = test[:, :test.shape[1]-1], test[:, test.shape[1]-1]\n",
        "print(test_x.shape, test_y.shape)"
      ],
      "metadata": {
        "id": "SZUR5vyslIa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means = np.mean(train_x, axis=0)\n",
        "stds = np.std(train_x, axis=0)  # [:5]\n",
        "print(means.shape, stds.shape)"
      ],
      "metadata": {
        "id": "fd2EwoWmlIa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = (train_x-means)/(stds + 0.000000001)\n",
        "val_x = (val_x-means)/(stds + 0.000000001)\n",
        "test_x = (test_x-means)/(stds + 0.000000001)\n",
        "real_test = (test_data-means)/(stds + 0.000000001)"
      ],
      "metadata": {
        "id": "Iwy_Mkp3lIa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(train_y == 0)"
      ],
      "metadata": {
        "id": "igEugQuBlIa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=16),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(units=4),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.1),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Dense(units=1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=[\"accuracy\", tf.keras.metrics.AUC()])"
      ],
      "metadata": {
        "id": "4RyLJYZSlIa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_x, train_y, epochs=500, validation_data=(val_x, val_y), batch_size=4096)"
      ],
      "metadata": {
        "id": "sTbVmHAmlIa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_x, test_y, batch_size=test_x.shape[0])"
      ],
      "metadata": {
        "id": "PwqvHjUQlIa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(real_test)\n",
        "print(preds.shape)"
      ],
      "metadata": {
        "id": "s7Dj5-mlkJwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uid_preds = dict(zip(test_uids, preds))\n",
        "print(len(uid_preds))"
      ],
      "metadata": {
        "id": "masdWVTEpUce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.DataFrame(uid_preds.items(), columns=[\"uid\", \"pred\"])"
      ],
      "metadata": {
        "id": "j07uSG_3tVQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.head()"
      ],
      "metadata": {
        "id": "35aeX1V_t2Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.pred = pred_df.pred.map(lambda arr: arr[0])\n",
        "pred_df.head()"
      ],
      "metadata": {
        "id": "Vr3MSrYUt3ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.to_csv(\"final_submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "Qi-rPIFHuBFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZDvfwURSuJO2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}